package programmingForDevelopers.zExercises.aArray;


    /*

    Exercises
    10.1-1
    Consider an m × n matrix in row-major order, where both m and n are
    powers of 2 and rows and columns are indexed from 0. We can represent
    a row index i in binary by the lg m bits 〈i
    lg m – 1, i
    lg m – 2, … , i0〉 and a
    column index j in binary by the lg n bits 〈j
    lg n – 1, j
    lg n – 2, … , j0〉.
    Suppose that this matrix is a 2 × 2 block matrix, where each block has
    m/2 rows and n/2 columns, and it is to be represented by a single array
    with 0-origin indexing. Show how to construct the binary representation
    of the (lg m + lg n)-bit index into the single array from the binary
    representations of i and j.
    */

public class Array1 {


}
